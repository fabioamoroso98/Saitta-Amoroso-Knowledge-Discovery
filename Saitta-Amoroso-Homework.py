# -*- coding: utf-8 -*-
"""HomeworkOneSaittaAmoroso.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pwZ0cszs6Vn5TibghCQcVs-CT1EOAaNX

The dataset used can't be uploaded in the GitHub repository because it exceeds the storage limits. It's possible to download it directly from Kaggle through the following link:

https://www.kaggle.com/datasets/alessiocorrado99/animals10

Just download it, upload it to your Google Drive and change the directories in the codes: it will work!

Libraries
"""

from google.colab import drive
import zipfile
import shutil
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader
from matplotlib import pyplot as plt
from tqdm.notebook import tqdm
from pathlib import Path
from PIL import Image
import os
import numpy as np
from sklearn.metrics import confusion_matrix
import pandas as pd
import seaborn as sn

"""Loading and creating the Dataset"""

# Access to google drive
drive.mount('/content/drive')

# Unzip the dataset
zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Animals.zip', 'r')
zip_ref.extractall('/content/Animals')
zip_ref.close()

rootdir= '/content/Animals/raw-img'

classes = ['cane', 'cavallo','farfalla', 'gallina', 'mucca', 'pecora', 'ragno', 'scoiattolo']

min = -1
for i in classes: 

    if len(os.listdir(rootdir + '/' + i)) < min or min == -1: 
       min = len(os.listdir(rootdir + '/' + i))

print(min)

rootdir= '/content/Animals'

classes = ['cane', 'cavallo', 'farfalla', 'gallina', 'mucca', 'pecora', 'ragno', 'scoiattolo']

for i in classes:
  os.makedirs('drive/MyDrive/AnimalsDSet/train/' + i)

  os.makedirs('drive/MyDrive/AnimalsDSet/test/' + i)

  os.makedirs('drive/MyDrive/AnimalsDSet/val/' + i)

  source = rootdir + '/raw-img/' + i

  allFileNames = os.listdir(source)

  np.random.shuffle(allFileNames)

  ##    0.80 = training ratio , (0.90-0.80) = validation ratio , (1-0.90) =  test ratio  
  train_animals, val_animals, test_animals = np.split(np.array(allFileNames[:min]),[int(len(allFileNames[:min])*0.80),int(len(allFileNames[:min])*0.90)])

  train_animals = [source+'/'+ name for name in train_animals.tolist()]
  val_animals = [source+'/' + name for name in val_animals.tolist()]
  test_animals = [source+'/' + name for name in test_animals.tolist()]


  for name in train_animals:
      shutil.copy(name, 'drive/MyDrive/AnimalsDSet/train/' + i)

  for name in val_animals:
      shutil.copy(name, 'drive/MyDrive/AnimalsDSet/test/' + i)

  for name in test_animals:
      shutil.copy(name, 'drive/MyDrive/AnimalsDSet/val/' + i)

class AnimalsDataset(Dataset):
  def __init__(self, dset_dir, train, val, transforms=T.Compose([])):
    if (train == True and val == False): 
      split = "train" 
    elif (train == False and val == False): 
      split = "test"
    elif (train == False and val == True):
     split = "val"
    else:
       print("train, val combination not allowed.")
       return

    self.dset_dir = Path(dset_dir)/split
    
    self.transforms = transforms

    self.files = []

    folders = sorted(os.listdir(self.dset_dir))
    for folder in folders:
      class_idx = folders.index(folder)

      folder_dir = self.dset_dir/folder

      files = os.listdir(folder_dir)

      self.files += [{"file": folder_dir/x, "class": class_idx} for x in files]

  def __len__(self):
    return len(self.files)

  def __getitem__(self, i):
    item = self.files[i]
    file = item['file']
    class_idx = torch.tensor(item['class'])

    img = Image.open(file).convert("RGB")
    img = self.transforms(img)
    return img, class_idx

transforms = T.Compose([
        T.Resize((64, 64)),
        T.RandomRotation((0, 20)),
        T.ToTensor(),
        T.Normalize(0.5, 0.5)
    ])

train_dset = AnimalsDataset('/content/drive/MyDrive/AnimalsDSet', train=True, val=False, transforms=transforms)
test_dset = AnimalsDataset('/content/drive/MyDrive/AnimalsDSet', train=False, val=False, transforms=transforms)
valid_dset = AnimalsDataset('/content/drive/MyDrive/AnimalsDSet', train=False, val=True, transforms=transforms)

data, label = train_dset[30]
data = data.permute(1,2,0)
print(data.shape)

plt.imshow(data)

train_loader = DataLoader(train_dset, batch_size=32, shuffle=True, drop_last=True, num_workers=2)
test_loader = DataLoader(test_dset, batch_size=32, shuffle=False, drop_last=False, num_workers=2)
valid_loader = DataLoader(valid_dset, batch_size=32, shuffle=False, drop_last=False, num_workers=2)

inputs, labels = next(iter(train_loader))
print(inputs.shape)
print(labels.shape)

"""CNN Models"""

class OneConvCNN(nn.Module):

  #Constructor
  def __init__(self, use_norm=False):
    # Call parent contructor
    super().__init__()
    self.layers = nn.Sequential(
      # Convolutional Layer 1
      nn.Conv2d(in_channels=3 , out_channels=64, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.BatchNorm2d(num_features=64)
    )
    
    # Fully-connected layers
    self.fc_layers = nn.Sequential(
      # FC layer
      nn.Linear(262144, 1024),
      nn.ReLU(),
      nn.Dropout(p=0.5),
      nn.BatchNorm1d(num_features=1024),
      # Classifier
      nn.Linear(1024, 8)
    )

  # Forward
  def forward(self, x):
    x = self.layers(x)
    x = x.view(x.size(0), -1)
    output = self.fc_layers(x)
    return output

netOne = OneConvCNN()
x = torch.rand(3, 3, 64, 64)
out = netOne(x)
print(out)
print(out.shape)

class TwoConvCNN(nn.Module):

  #Constructor
  def __init__(self, use_norm=False):
    # Call parent contructor
    super().__init__()
    self.layers = nn.Sequential(
      # Convolutional Layer 1
      nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.BatchNorm2d(num_features=64),
      # Convolutional Layer 2
      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=128)
    )
    
    # Fully-connected layers
    self.fc_layers = nn.Sequential(
      # FC layer
      nn.Linear(131072, 1024),
      nn.ReLU(),
      nn.Dropout(p=0.5),
      nn.BatchNorm1d(num_features=1024),
      # Classifier
      nn.Linear(1024, 8)
    )

  # Forward
  def forward(self, x):
    x = self.layers(x)
    x = x.view(x.size(0), -1)
    output = self.fc_layers(x)
    return output

netTwo = TwoConvCNN()
x = torch.rand(3, 3, 64, 64)
out = netTwo(x)
print(out)
print(out.shape)

class ThreeConvCNN(nn.Module):

  #Constructor
  def __init__(self, use_norm=False):
    # Call parent contructor
    super().__init__()
    self.layers = nn.Sequential(
      # Convolutional Layer 1
      nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.BatchNorm2d(num_features=64),
      # Convolutional Layer 2
      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=128),
      # Convolutional Layer 3
      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=256)
    )
    
    # Fully-connected layers
    self.fc_layers = nn.Sequential(
      # FC layer
      nn.Linear(65536, 1024),
      nn.ReLU(),
      nn.Dropout(p=0.5),
      nn.BatchNorm1d(num_features=1024),
      # Classifier
      nn.Linear(1024, 8)
    )

  # Forward
  def forward(self, x):
    x = self.layers(x)
    x = x.view(x.size(0), -1)
    output = self.fc_layers(x)
    return output

netThree = ThreeConvCNN()
x = torch.rand(3, 3, 64, 64)
out = netThree(x)
print(out)
print(out.shape)

class FourConvCNN(nn.Module):

  #Constructor
  def __init__(self, use_norm=False):
    # Call parent contructor
    super().__init__()
    self.layers = nn.Sequential(
      # Convolutional Layer 1
      nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.BatchNorm2d(num_features=64),
      # Convolutional Layer 2
      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=128),
      # Convolutional Layer 3
      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=256),
      # Convolutional Layer 4
      nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=512)
    )
    
    # Fully-connected layers
    self.fc_layers = nn.Sequential(
      # FC layer
      nn.Linear(32768, 1024),
      nn.ReLU(),
      nn.Dropout(p=0.5),
      nn.BatchNorm1d(num_features=1024),
      # Classifier
      nn.Linear(1024, 8)
    )

  # Forward
  def forward(self, x):
    x = self.layers(x)
    x = x.view(x.size(0), -1)
    output = self.fc_layers(x)
    return output

netFour = FourConvCNN()
x = torch.rand(3, 3, 64, 64)
out = netFour(x)
print(out)
print(out.shape)

class FiveConvCNN(nn.Module):

  #Constructor
  def __init__(self, use_norm=False):
    # Call parent contructor
    super().__init__()
    self.layers = nn.Sequential(
      # Convolutional Layer 1
      nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.BatchNorm2d(num_features=64),
      # Convolutional Layer 2
      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=128),
      # Convolutional Layer 3
      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=256),
      # Convolutional Layer 4
      nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=512),
      # Convolutional Layer 5
      nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=1024)
    )
    
    # Fully-connected layers
    self.fc_layers = nn.Sequential(
        # FC layer
        nn.Linear(16384, 1024),
        nn.ReLU(),
        nn.Dropout(p=0.5),
        nn.BatchNorm1d(num_features=1024),
        # Classifier
        nn.Linear(1024, 8)
    )

  # Forward
  def forward(self, x):
    x = self.layers(x)
    x = x.view(x.size(0), -1)
    output = self.fc_layers(x)
    return output

netFive = FiveConvCNN()
x = torch.rand(3, 3, 64, 64)
out = netFive(x)
print(out)
print(out.shape)

class SixConvCNN(nn.Module):

  #Constructor
  def __init__(self, use_norm=False):
    # Call parent contructor
    super().__init__()
    self.layers = nn.Sequential(
      # Convolutional Layer 1
      nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.BatchNorm2d(num_features=64),
      # Convolutional Layer 2
      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=128),
      # Convolutional Layer 3
      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=256),
      # Convolutional Layer 4
      nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=512),
      # Convolutional Layer 5
      nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=1024),
      # Convolutional Layer 6
      nn.Conv2d(in_channels=1024, out_channels=2048, kernel_size=3, padding=1, stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=2, stride=2),
      nn.BatchNorm2d(num_features=2048)
    )
    
    # Fully-connected layers
    self.fc_layers = nn.Sequential(
        # FC layer
        nn.Linear(8192, 1024),
        nn.ReLU(),
        nn.Dropout(p=0.5),
        nn.BatchNorm1d(num_features=1024),
        # Classifier
        nn.Linear(1024, 8)
    )

  # Forward
  def forward(self, x):
    x = self.layers(x)
    x = x.view(x.size(0), -1)
    output = self.fc_layers(x)
    return output

netSix = SixConvCNN()
x = torch.rand(3, 3, 64, 64)
out = netSix(x)
print(out)
print(out.shape)

"""Training"""

def train(net, loaders, optimizer, criterion, epochs, dev=torch.device("cpu"), save_param = False, model_name = 'main_model'):
    try:
        net = net.to(dev)
        #print(net)
        # Initialize history
        history_loss = {"train": [], "val": [], "test": []}
        history_accuracy = {"train": [], "val": [], "test": []}
        # Store the best val accuracy
        best_val_accuracy = 0

        # Process each epoch
        for epoch in range(epochs):
            # Initialize epoch variables
            sum_loss = {"train": 0, "val": 0, "test": 0}
            sum_accuracy = {"train": 0, "val": 0, "test": 0}
            # Process each split
            for split in ["train", "val", "test"]:
                if split == "train":
                  net.train()
                else:
                  net.eval()
                # Process each batch
                for (input, labels) in tqdm(loaders[split],desc=split):
                    # Move to CUDA
                    input = input.to(dev)
                    labels = labels.to(dev)
                    # Reset gradients
                    optimizer.zero_grad()
                    # Compute output
                    pred = net(input)
                    loss = criterion(pred, labels)
                    # Update loss
                    sum_loss[split] += loss.item()
                    # Check parameter update
                    if split == "train":
                        # Compute gradients
                        loss.backward()
                        # Optimize
                        optimizer.step()
                    # Compute accuracy
                    _,pred_labels = pred.max(1)
                    batch_accuracy = (pred_labels == labels).sum().item()/input.size(0)
                    # Update accuracy
                    sum_accuracy[split] += batch_accuracy
            # Compute epoch loss/accuracy
            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in ["train", "val", "test"]}
            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in ["train", "val", "test"]}

            # Store params at the best validation accuracy
            if save_param and epoch_accuracy["val"] > best_val_accuracy:
              #torch.save(net.state_dict(), f"{net.__class__.__name__}_best_val.pth")
              torch.save(net.state_dict(), f"{model_name}_best_val.pth")
              best_val_accuracy = epoch_accuracy["val"]

            # Update history
            for split in ["train", "val", "test"]:
                history_loss[split].append(epoch_loss[split])
                history_accuracy[split].append(epoch_accuracy[split])
            # Print info
            print(f"Epoch {epoch+1}:",
                  f"TrL={epoch_loss['train']:.4f},",
                  f"TrA={epoch_accuracy['train']:.4f},",
                  f"VL={epoch_loss['val']:.4f},",
                  f"VA={epoch_accuracy['val']:.4f},",
                  f"TeL={epoch_loss['test']:.4f},",
                  f"TeA={epoch_accuracy['test']:.4f},")
    except KeyboardInterrupt:
        print("Interrupted")
    finally:
        # Plot loss
        plt.title("Loss")
        for split in ["train", "val", "test"]:
            plt.plot(history_loss[split], label=split)
        plt.legend()
        plt.show()
        # Plot accuracy
        plt.title("Accuracy")
        for split in ["train", "val", "test"]:
            plt.plot(history_accuracy[split], label=split)
        plt.legend()
        plt.show()

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(device)

net = OneConvCNN()
optimizer = optim.SGD(net.parameters(), lr = 0.005)
criterion = nn.CrossEntropyLoss()


# Define dictionary of loaders
loaders = {"train": train_loader,
           "val": valid_loader,
           "test": test_loader}

train(net, loaders, optimizer, criterion, epochs=25, dev=device)

net = TwoConvCNN()

train(net, loaders, optimizer, criterion, epochs=25, dev=device)

net = ThreeConvCNN()

train(net, loaders, optimizer, criterion, epochs=25, dev=device)

net = FourConvCNN()

train(net, loaders, optimizer, criterion, epochs=25, dev=device)

net = FiveConvCNN()

train(net, loaders, optimizer, criterion, epochs=25, dev=device)

net = SixConvCNN()

train(net, loaders, optimizer, criterion, epochs=30, dev=device, save_param = True)

y_pred = []
y_true = []

# iterate over test data
for inputs, labels in test_loader:
        inputs = inputs.cuda()
        labels = labels.cuda()
        output = net(inputs) # Feed Network

        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
        y_pred.extend(output) # Save Prediction
        
        labels = labels.data.cpu().numpy()
        y_true.extend(labels) # Save Truth

# constant for classes
classes = ['cane', 'cavallo','farfalla', 'gallina', 'mucca', 'pecora', 'ragno', 'scoiattolo']

# Build confusion matrix
cf_matrix = confusion_matrix(y_true, y_pred)
df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) * 8, index = [i for i in classes],
                     columns = [i for i in classes])
plt.figure(figsize = (12,7))
sn.heatmap(df_cm, annot=True)